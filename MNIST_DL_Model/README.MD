# MNIST Benchmarking: PyTorch vsâ€¯MLX (Singleâ€‘node & Distributed)

<h1>ğŸ§­ Project Overview</h1>
This project compares two simple MNIST classifiers (PyTorch and MLX) on Apple Silicon (MacBook & Mac Mini) to evaluate performance differences in:

1. Model Implementation

2. Training & Evaluation (Singleâ€‘node)

3. Distributed Training (PyTorch)

Everythingâ€™s tracked in detail via metrics: accuracy, inference time, throughput, memory usage, CPU/GPU utilization.


<h1>ğŸ“ Repository Structure </h1>

     MLXProj/
    â”œâ”€â”€ training/
    â”‚   â”œâ”€â”€ train_pytorch.py
    â”‚   â”œâ”€â”€ train_pytorch_ddp.py
    â”‚   â”œâ”€â”€ train_mlx.py
    â”‚â”€â”€ evaluation/
    â”‚   â””â”€â”€ eval_benchmark.py
    |   |__ eval_pytorch.py
    |   |__ eval_benchmark_ddp.py
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ pytorch_model.py
    â”‚   â””â”€â”€ mlx_model.py
    â”œâ”€â”€ results/               # Saved models & logs
    â””â”€â”€ README.md


<h1>ğŸ› ï¸ Environment Setup</h1>

OS: macOS (MacBookPro (M3 Pro Chip), & 2 Mac Mini's (M4 Pro chips))

Python: 3.13 virtual environment env_mlx

Dependencies: torch, torchvision, mlx, psutil, memory_profiler

Metal/Developer Tools installed (xcode-select)


<h1> ğŸ”„ Singleâ€‘Node Experiments </h1>

1. PyTorch (Nonâ€‘MLX)

train_pytorch.py trains a simple 2â€‘layer MLP on MNIST

eval_benchmark.py logs:

Accuracy (~97.5â€“97.6%)

Inference time (~0.14â€“0.20â€¯s, ~50â€‘70k samples/sec)

CPU memory (~300â€¯MB), CPU usage (~2â€“4%), GPU for MLX only

âœ… Trained & evaluated on MacBook & Mac Mini individually








